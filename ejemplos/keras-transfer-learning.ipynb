{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsFozCAx9r4g"
   },
   "source": [
    "# **Redes Convolucionales Profundas (CNNs)**\n",
    "## **Ejercicio: clasificar en female / male caras en color**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJbLizBOTs6x"
   },
   "source": [
    "La base de datos usada es un subconjunto de la base de datos\n",
    "\"Labeled Faces in the Wild\" (\"LFW\"):\n",
    "\n",
    "  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz\n",
    "\n",
    "  http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "La separación en carpetas \"female\" / \"male\" se ha realizado usando\n",
    "un código basado en:\n",
    "https://github.com/Pletron/LFWgender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yjN2rcFTs6q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K17jfrfMZdYs"
   },
   "outputs": [],
   "source": [
    "COLAB = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeJKZ-SdZfml"
   },
   "source": [
    "Si se desea ejecutar en local:\n",
    "\n",
    "- Descargar el dataset de: https://drive.google.com/file/d/1kD_GKuU2doz3TSNVi45_BbwvDZ2KmEei\n",
    "\n",
    "- Poner variable COLAB a False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXc50-rN3IQ2"
   },
   "outputs": [],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulBPjhnBBhbm"
   },
   "source": [
    "### Descarga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-eKTevppZdbI"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    aux = \"'https://drive.usercontent.google.com/download?id=1kD_GKuU2doz3TSNVi45_BbwvDZ2KmEei&export=download&confirm=t&uuid=56f4f47a-291b-4ef9-895f-8886caf14b78'\"\n",
    "    !wget $aux -O ./gender.zip\n",
    "    !unzip -qq ./gender.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nktDNpqu3WvC"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "    gdd.download_file_from_google_drive(file_id='1jifedd49sgZI2ZA6722h9R-mRh2Ciqzp',\n",
    "                                        dest_path='./caras_aux.py.zip', unzip=True)\n",
    "    gdd.download_file_from_google_drive(file_id='1w6rSNy0mDds1cDNBtbL9U1bkF4PiGCnK',\n",
    "                                        dest_path='./funciones_auxiliares.py.zip', unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "288pPq6V_nEv"
   },
   "source": [
    "## **Funciones auxiliares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNNx13G5AAvB"
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "\n",
    "def display_model(model):\n",
    "    if COLAB:\n",
    "        display(SVG(model_to_dot(model, show_shapes=True,dpi=72).create(prog='dot', format='svg')))\n",
    "    else:\n",
    "        display(SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dr7-texQAx0a"
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def grafica_entrenamiento(tr_acc, val_acc, tr_loss, val_loss,\n",
    "                          figsize=(10,4)):\n",
    "    #best_i = np.argmax(val_acc)\n",
    "    best_i = np.argmin(val_loss)\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.subplot(1,2,1)\n",
    "    plt.plot(1+np.arange(len(tr_acc)),  100*np.array(tr_acc))\n",
    "    plt.plot(1+np.arange(len(val_acc)), 100*np.array(val_acc))\n",
    "    plt.plot(1+best_i, 100*val_acc[best_i], 'or')\n",
    "    plt.title('tasa de acierto del modelo (%)', fontsize=18)\n",
    "    plt.ylabel('tasa de acierto (%)', fontsize=18)\n",
    "    plt.xlabel('época', fontsize=18)\n",
    "    plt.legend(['entrenamiento', 'validación'], loc='upper left')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(1+np.arange(len(tr_acc)), np.array(tr_loss))\n",
    "    plt.plot(1+np.arange(len(val_acc)), np.array(val_loss))\n",
    "    plt.plot(1+best_i, val_loss[best_i], 'or')\n",
    "    plt.title('loss del modelo', fontsize=18)\n",
    "    plt.ylabel('loss', fontsize=18)\n",
    "    plt.xlabel('época', fontsize=18)\n",
    "    plt.legend(['entrenamiento', 'validación'], loc='upper left')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tADEGzcEZmGK"
   },
   "outputs": [],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBvFmi-b95yl"
   },
   "source": [
    "## **Exploración de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-BnrIIm0Tkg"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from keras.utils import load_img\n",
    "\n",
    "ficheros_male = sorted(glob(\"./gender/male/*\"))\n",
    "ficheros_male[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-u_q46w0TnY"
   },
   "outputs": [],
   "source": [
    "for fich in ficheros_male[:10]:\n",
    "    imagen = load_img(fich)\n",
    "    display(imagen)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQVKzrsQ0TqZ"
   },
   "outputs": [],
   "source": [
    "ficheros_female = sorted(glob(\"./gender/female/*\"))\n",
    "for fich in ficheros_female[:10]:\n",
    "    imagen = load_img(fich)\n",
    "    display(imagen)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7itkI3O-C_7"
   },
   "source": [
    "### **Función para normalizar los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ru6GMxa2AFS"
   },
   "outputs": [],
   "source": [
    "np.array(imagen).min(), np.array(imagen).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoVnfRRh2tJO"
   },
   "outputs": [],
   "source": [
    "preprocess_input = lambda x:x/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WX1W4FSX-W7f"
   },
   "source": [
    "### **Partición training-test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxvTBF-uTs63"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rutas = pd.DataFrame({\"path\": ficheros_female+ficheros_male, \"class\": [\"female\"]*len(ficheros_female) + [\"male\"]*len(ficheros_male)})\n",
    "rutas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0p1tsdoluE7a"
   },
   "source": [
    "Problema: un/a famoso/a puede tener varias fotografías. La idea es que todas ellas deberían estar o bien en training, o en validación, o en test, pero no en varios conjuntos a la vez. Si no, podría ocurrir que en test evaluemos a la red con los mismos personajes con los que hemos entrenado.\n",
    "\n",
    "Solución: la partición training/validación/test la hago con los personajes. Una vez que tengo esa partición a nivel de personajes, meto en cada conjunto todas las fotos de los personajes correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgJSmcqNt_sK"
   },
   "outputs": [],
   "source": [
    "\"_\".join(ficheros_female[0].split(\"_\")[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVlEFlOnt_vF"
   },
   "outputs": [],
   "source": [
    "ficheros_female2 = [\"_\".join(ruta.split(\"_\")[:-1]) for ruta in ficheros_female]\n",
    "ficheros_female2 = sorted(list(set(ficheros_female2)))\n",
    "etiquetas_female2 = len(ficheros_female2)*[\"female\"]\n",
    "print(ficheros_female2[:3])\n",
    "print(etiquetas_female2[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6CnoLo-t_yQ"
   },
   "outputs": [],
   "source": [
    "ficheros_male2 = [\"_\".join(ruta.split(\"_\")[:-1]) for ruta in ficheros_male]\n",
    "ficheros_male2 = sorted(list(set(ficheros_male2)))\n",
    "etiquetas_male2 = len(ficheros_male2)*[\"male\"]\n",
    "print(ficheros_male2[:3])\n",
    "print(etiquetas_male2[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yD82qxUPt_1U"
   },
   "outputs": [],
   "source": [
    "rutas2 = ficheros_female2 + ficheros_male2\n",
    "etiquetas2 = etiquetas_female2 + etiquetas_male2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPenZlBpt_3-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rutas2_trval, rutas2_test, ets2_trval, ets2_test = train_test_split(rutas2, etiquetas2,\n",
    "                                                                    test_size=0.3, random_state=1,\n",
    "                                                                    stratify=etiquetas2)\n",
    "rutas2_tr, rutas2_val, ets2_tr, ets2_val = train_test_split(rutas2_trval, ets2_trval,\n",
    "                                                                    test_size=0.3, random_state=1,\n",
    "                                                                    stratify=ets2_trval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0FwrJmkt_6n"
   },
   "outputs": [],
   "source": [
    "rutas2_tr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClDOXvhft_9M"
   },
   "outputs": [],
   "source": [
    "rutas2_val[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_7GTyvUuAAP"
   },
   "outputs": [],
   "source": [
    "rutas2_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yeBb0xV8uAC5"
   },
   "outputs": [],
   "source": [
    "# rutas detalladas:\n",
    "rutas     = ficheros_female + ficheros_male\n",
    "etiquetas = [\"female\"]*len(ficheros_female) + [\"male\"]*len(ficheros_male)\n",
    "\n",
    "# rutas detalladas por conjunto (tr, val, test):\n",
    "rutas3_tr = []\n",
    "ets3_tr = []\n",
    "\n",
    "rutas3_val = []\n",
    "ets3_val = []\n",
    "\n",
    "rutas3_test = []\n",
    "ets3_test = []\n",
    "\n",
    "for x,y in zip(rutas, etiquetas):\n",
    "    aux = \"_\".join(x.split(\"_\")[:-1])\n",
    "    if aux in rutas2_tr:\n",
    "        rutas3_tr.append(x)\n",
    "        ets3_tr.append(y)\n",
    "    elif aux in rutas2_val:\n",
    "        rutas3_val.append(x)\n",
    "        ets3_val.append(y)\n",
    "    else:\n",
    "        rutas3_test.append(x)\n",
    "        ets3_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsAOHlNJuTKq"
   },
   "outputs": [],
   "source": [
    "len(rutas3_tr) + len(rutas3_val) + len(rutas3_test), len(rutas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPw4hM6huTNf"
   },
   "outputs": [],
   "source": [
    "rutas_tr = pd.DataFrame({\"path\": rutas3_tr, \"class\": ets3_tr})\n",
    "rutas_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUJiGNj7uTQU"
   },
   "outputs": [],
   "source": [
    "rutas_val = pd.DataFrame({\"path\": rutas3_val, \"class\": ets3_val})\n",
    "rutas_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bp2YXuLluAFe"
   },
   "outputs": [],
   "source": [
    "rutas_test = pd.DataFrame({\"path\": rutas3_test, \"class\": ets3_test})\n",
    "rutas_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gwly3Tbo-Zpb"
   },
   "source": [
    "### **Estadísticas de las clases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1FmoRuvTs7C"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "ax = plt.subplot(1,3,1)\n",
    "clases, counts = np.unique(rutas_tr[\"class\"], return_counts=True)\n",
    "plt.bar(clases, 100*counts/len(rutas_tr), color=[\"blue\", \"orange\"])\n",
    "plt.title('Training'); plt.xlabel('Clase'); plt.ylabel('Frequency (%)'); ax.set_xticks(clases)\n",
    "\n",
    "ax = plt.subplot(1,3,2)\n",
    "clases, counts = np.unique(rutas_val[\"class\"], return_counts=True)\n",
    "plt.bar(clases, 100*counts/len(rutas_val), color=[\"blue\", \"orange\"])\n",
    "plt.title('Validación'); plt.xlabel('Clase'); plt.ylabel('Frequency (%)'); ax.set_xticks(clases)\n",
    "\n",
    "ax = plt.subplot(1,3,3)\n",
    "none, counts = np.unique(rutas_test[\"class\"], return_counts=True)\n",
    "plt.bar(clases, 100*counts/len(rutas_test), color=[\"blue\", \"orange\"])\n",
    "plt.title('Test'); plt.xlabel('Clase'); ax.set_xticks(clases); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DEL9nkdMh1r"
   },
   "source": [
    "## **Implementación en Keras de un modelo que clasifique una cara en color en female / male**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXqgW615pvO6"
   },
   "source": [
    "https://keras.io/api/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77XP4HfF_fEF"
   },
   "outputs": [],
   "source": [
    "# dimensiones a las que vamos a llevar las imágenes\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "normed_dims = (img_height, img_width)\n",
    "normed_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-8BPV6_pzoq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34DeMYbI3GxP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubnaTJ0A3G05"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAh9q01Up7uu"
   },
   "outputs": [],
   "source": [
    "# completar código con modelo de transfer learning\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3FsJbdRAAsJ"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUWwkr5Q_fcB"
   },
   "outputs": [],
   "source": [
    "display_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFUy_3-lAwU9"
   },
   "source": [
    "## **Entrenamiento del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_mH9L3J4fw3"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HcBZl6dq8dj"
   },
   "outputs": [],
   "source": [
    "# data augmentation:\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    dtype='float32',\n",
    "    preprocessing_function = preprocess_inputlambda x:x/255, # para visualizar el data augmentation no usamos el preprocess_input de resnet50\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    #fill_mode='nearest',\n",
    "    #fill_mode='constant',\n",
    "    fill_mode='mirror',\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "imagen_num = np.expand_dims(np.array(imagen), axis=0)\n",
    "for i in range(10):\n",
    "    plt.imshow(train_datagen.flow(imagen_num)[0][0])\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ULB0sLi212i"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    dtype='float32',\n",
    "    preprocessing_function = preprocess_input,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen  = ImageDataGenerator(dtype='float32',\n",
    "                                  preprocessing_function = preprocess_input)\n",
    "\n",
    "test_datagen = ImageDataGenerator(dtype='float32',\n",
    "                                  preprocessing_function = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dfy4uIWf4d-c"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=rutas_tr,\n",
    "    x_col=\"path\",\n",
    "    y_col=\"class\",\n",
    "    target_size=normed_dims,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical') # binary, categorical, sparse\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=rutas_val,\n",
    "    x_col=\"path\",\n",
    "    y_col=\"class\",\n",
    "    target_size=normed_dims,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical') # binary, categorical, sparse\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=rutas_test,\n",
    "    x_col=\"path\",\n",
    "    y_col=\"class\",\n",
    "    target_size=normed_dims,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical') # binary, categorical, sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5SlIXcO62PK"
   },
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0HbgWS_62SM"
   },
   "outputs": [],
   "source": [
    "number_train_samples = train_generator.n\n",
    "number_val_samples   = validation_generator.n\n",
    "number_test_samples  = test_generator.n\n",
    "\n",
    "number_train_samples, number_val_samples, number_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nn0EvVaAx13"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "modelpath=\"best_model.h5\"\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "checkpoint = ModelCheckpoint(modelpath, monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min') # graba sólo los que mejoran en validación\n",
    "\n",
    "serie_tr_acc = []\n",
    "serie_val_acc = []\n",
    "serie_tr_loss  = []\n",
    "serie_val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQGhpc2WAyDM"
   },
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    salida = model.fit(train_generator,\n",
    "                       steps_per_epoch=number_train_samples // batch_size,\n",
    "                       epochs=1,\n",
    "                       callbacks=[checkpoint],\n",
    "                       verbose=1,\n",
    "                       shuffle = True,\n",
    "                       validation_data=validation_generator,\n",
    "                       validation_steps=number_val_samples // batch_size\n",
    "                      )\n",
    "\n",
    "    serie_tr_acc.append(salida.history[\"accuracy\"][0])\n",
    "    serie_val_acc.append(salida.history[\"val_accuracy\"][0])\n",
    "    serie_tr_loss.append(salida.history[\"loss\"][0])\n",
    "    serie_val_loss.append(salida.history[\"val_loss\"][0])\n",
    "\n",
    "    clear_output()\n",
    "    grafica_entrenamiento(serie_tr_acc, serie_val_acc,\n",
    "                          serie_tr_loss, serie_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROW4nkrbA0bF"
   },
   "source": [
    "Recupero el mejor modelo (punto rojo), que está grabado en el fichero dado por la variable modelpath:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiJkL1mIAyGh"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jh_MIdQQBDbb"
   },
   "source": [
    "## **Análisis de los resultados del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCCmVJdk8OPX"
   },
   "outputs": [],
   "source": [
    "scores_tr = model.evaluate(train_generator)\n",
    "print('Train loss    :', scores_tr[0])\n",
    "print('Train accuracy:', scores_tr[1])\n",
    "print()\n",
    "\n",
    "scores_val = model.evaluate(validation_generator)\n",
    "print('Val loss    :', scores_val[0])\n",
    "print('Val accuracy:', scores_val[1])\n",
    "print()\n",
    "\n",
    "scores_te = model.evaluate(test_generator)\n",
    "print('Test loss     :', scores_te[0])\n",
    "print('Test accuracy :', scores_te[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iReXlBPd8OSA"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "\n",
    "y_real = np.array(test_generator.classes)\n",
    "y_pred_proba = model.predict(test_generator)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "print('')\n",
    "print(classification_report(y_real, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugmu6a9r8OVA"
   },
   "outputs": [],
   "source": [
    "clase_positiva = 1\n",
    "fpr, tpr, thresholds = roc_curve(y_real==clase_positiva, y_pred_proba[:,clase_positiva])\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.plot(fpr, tpr, 'r-.', label = 'CNN (%2.2f)' % auc(fpr, tpr))\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.plot(fpr, fpr, 'b-', label = 'Random Guess')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ww54-sEf8dyP"
   },
   "source": [
    "## **Visualización de ejemplos de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iX-4zv188OXu"
   },
   "outputs": [],
   "source": [
    "test_datagen2 = ImageDataGenerator(dtype='float32') # ahora no preproceso aquí\n",
    "\n",
    "test_generator2 = test_datagen2.flow_from_dataframe(\n",
    "    dataframe=rutas_test,\n",
    "    x_col=\"path\",\n",
    "    y_col=\"class\",\n",
    "    target_size=normed_dims,\n",
    "    batch_size=test_generator.n, # todas las imágenes del directorio test\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "haX6RlmI8Ob8"
   },
   "outputs": [],
   "source": [
    "test_generator2.reset()\n",
    "X_te, y_te = test_generator2.next()\n",
    "class_indices = test_generator2.class_indices\n",
    "class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiTLu0kd8OdM"
   },
   "outputs": [],
   "source": [
    "ind_te1 = 1 # 1500\n",
    "\n",
    "image = X_te[ind_te1].copy()\n",
    "\n",
    "plt.imshow(image/255)\n",
    "plt.axis(\"off\")\n",
    "p = model.predict(preprocess_input(np.expand_dims(image.copy(), axis=0)))[0][class_indices[\"female\"]]\n",
    "print(\"Probabilidad female: {:2.1f}%\".format(100*p))\n",
    "p = model.predict(preprocess_input(np.expand_dims(image.copy(), axis=0)))[0][class_indices[\"male\"]]\n",
    "print(\"Probabilidad male : {:2.1f}%\".format(100*p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prhy4Snw8tat"
   },
   "source": [
    "## **Visualización del funcionamiento de la red**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOFUu5b48rCH"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "ejemplo = 0\n",
    "\n",
    "N = 16\n",
    "\n",
    "# Now we extract the outputs of the top 6 layers:\n",
    "layer_outputs = [layer.output for layer in model.layers[2:N]]\n",
    "# Creates a model that will return these outputs, given the model input:\n",
    "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "activations = activation_model.predict(preprocess_input(X_te[ejemplo:(ejemplo+1)].copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-_sWxJG8rE3"
   },
   "outputs": [],
   "source": [
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = []\n",
    "for layer in model.layers[2:N]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "# Now let's display our feature maps\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    # This is the number of features in the feature map\n",
    "    n_features = layer_activation.shape[-1]\n",
    "\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = layer_activation.shape[1]\n",
    "\n",
    "    # We will tile the activation channels in this matrix\n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "    # We'll tile each filter into this big horizontal grid\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            # Post-process the feature to make it visually palatable\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size,\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "    # Display the grid\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kThS68AC82gF"
   },
   "source": [
    "### **¿A qué partes de la imagen de entrada es más sensible la salida de la red?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYejS49I85D4"
   },
   "source": [
    "### **GradCam:**\n",
    "\n",
    "(de https://medium.com/analytics-vidhya/visualizing-activation-heatmaps-using-tensorflow-5bdba018f759)\n",
    "\n",
    "1- Calcular para una imagen la salida del modelo y la salida de la última capa convolucional\n",
    "\n",
    "2- Encuentrar la neurona de salida más activa (que es la que determina la clase predicha)\n",
    "\n",
    "3- Calcular el gradiente de dicha neurona de salida con respecto a la última capa convolucional\n",
    "\n",
    "3- Promediar y pesar esto con la salida de la última capa convolucional\n",
    "\n",
    "4- Normalizar entre 0 y 1 para visualizar\n",
    "\n",
    "5- Convertir a RGB y superponerla a la imagen original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUgiE2uT8rHx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "\n",
    "def find_ind_last_conv2D(model):\n",
    "    ind_last_conv2D_layer = None\n",
    "    for i,x in enumerate(model.layers):\n",
    "        if x.__class__.__name__ == \"Conv2D\":\n",
    "            ind_last_conv2D_layer = i\n",
    "    return ind_last_conv2D_layer\n",
    "\n",
    "\n",
    "def show_heatmap(model, im, heatmap_factor=0.5, cmap=cv2.COLORMAP_HOT):\n",
    "    imag = np.expand_dims(im, axis=0) # de 1 imagen pasamos a 1 conjunto de 1 imagen\n",
    "\n",
    "    # The is the output feature map of the last convolutional layer\n",
    "    last_conv_layer = model.layers[find_ind_last_conv2D(model)]\n",
    "\n",
    "    # This is the gradient of the \"benign\" class with regard to\n",
    "    # the output feature map of last convolutional layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        aux = model.output\n",
    "        #aux = model.layers[-2].output # salida de la última capa densa antes de softmax\n",
    "\n",
    "        iterate = tf.keras.models.Model([model.inputs], [aux, last_conv_layer.output])\n",
    "        model_out, last_conv_layer = iterate(preprocess_input(imag.copy())) # ***\n",
    "        class_out = model_out[:, np.argmax(model_out[0])]\n",
    "        grads = tape.gradient(class_out, last_conv_layer)\n",
    "\n",
    "        # mean intensity of the gradient over a specific feature map channel:\n",
    "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0) # se quitan los negativos (se ponen a 0)\n",
    "    heatmap /= np.max(heatmap) # se normaliza entre 0 y 1\n",
    "    heatmap = heatmap[0] # pasamos de 1 conjunto de 1 heatmap a 1 heatmap\n",
    "\n",
    "    img = imag[0]\n",
    "\n",
    "    img = np.zeros((im.shape[0],im.shape[1],3))\n",
    "    for i in range(3):\n",
    "        img[:,:,i] = imag[0,:,:,0]\n",
    "\n",
    "\n",
    "    # We resize the heatmap to have the same size as the original image\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # We convert the heatmap to RGB\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # We apply the heatmap to the original image\n",
    "    heatmap = cv2.applyColorMap(heatmap, cmap) / 255\n",
    "\n",
    "\n",
    "    im2 = (im - im.min()) / (im.max() - im.min())\n",
    "    superimposed_img = (1-heatmap_factor)*im2 + heatmap_factor*heatmap\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(im2, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(heatmap, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(superimposed_img, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])\n",
    "    plt.show()\n",
    "    prob = 100*model.predict(imag)[0][class_indices[\"female\"]]\n",
    "    print(\"Probabilidad clase female : {:2.1f}%\".format(prob))\n",
    "    prob = 100*model.predict(imag)[0][class_indices[\"male\"]]\n",
    "    print(\"Probabilidad clase male: {:2.1f}%\".format(prob))\n",
    "    print(\"\\n\\n\")\n",
    "    return heatmap, superimposed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuYF1l7B9CHM"
   },
   "source": [
    "**Visualización de mapas de sensibilidades (heatmaps) en varios ejemplos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_2RFriv8_zf"
   },
   "outputs": [],
   "source": [
    "ind = 20\n",
    "\n",
    "for i in range(ind, ind+10):\n",
    "    show_heatmap(model, X_te[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KgW5gvRyUtN"
   },
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "    ind = np.random.randint(len(X_te))\n",
    "    show_heatmap(model, X_te[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CP4RvDCN10Mb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "kThS68AC82gF"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
